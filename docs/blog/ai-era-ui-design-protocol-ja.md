# AI時代の画面設計の限界：「動くUI」をAIにどう伝えるか？

## はじめに

AIを活用した開発をしていると、ある壁にぶつかります。

**「複雑なUIの動作や遷移を、AIにどう正確に伝えるか？」**

Figmaなどのビジュアルデザインツールは、画面の「見た目」を定義する上では強力です。しかし、ユーザーの操作による「状態変化」や「画面遷移」になると、AIへの指示が上手くいかないことがあります。

例えば、こんな要件：

> 「フォームAに3文字未満で入力している間は、ボタンBを非活性にして、エラーメッセージを出す」

これをデザインカンプだけでAIに伝えても、期待通りのコードは出てきません。

---

## 仮説：「動作」をテキストで定義すれば伝わるのでは？

AIは宣言的なテキスト定義との相性が良いです。「UIがどうあるべきか」をテキストで受け取ると、コードの骨格を生成しやすい。

ならば、**画面の「動作」と「遷移」を構造化テキストで定義すれば、AIが正確に解釈できるのでは？**

この仮説を検証するため、YAMLベースのプロトコルを試作してみました。

---

## 試作：画面振る舞いプロトコル

### 定義する3つの要素

1. **構成（Structure）**: コンポーネントの種類、親子関係
2. **動作（Behavior）**: ユーザー操作に対する状態変化のルール
3. **遷移（Transition）**: 画面間・レイヤー間の移動ルール

### 書き方の例

```yaml
screens:
  SettingPage:
    state:
      form:
        type: form
        schema: SettingForm

    computed:
      isFormValid:
        all of:
          - name is not empty
          - email contains "@"

    layout:
      - TextField:
          label: 名前
          value: form.name
          on:change: set form.name to {value}

      - Button:
          label: 設定を保存
          disabled: not isFormValid
          on:click: actions.saveAndApprove
```

ポイントは：
- **自然言語に近い構文**: `name is not empty`, `email contains "@"`
- **プログラミング知識なしで読める**: 「名前が空だとボタン押せない」とわかる

---

## 検証：AIに作らせてみる

このプロトコルを使って、複雑なUIをAIに作らせてみます。

### 検証1: Figma Makeに渡す

プロトコルをFigma Makeに渡して「これに基づいてUIを作って」とお願い。

→ **結果**: （実験後に追記）

### 検証2: コーディングAI（Claude）に渡す

同じプロトコルをClaudeに渡して「React + MUIで実装して」とお願い。

→ **結果**: （実験後に追記）

---

## 期待している効果

もし両方で意図が伝わるなら、こんな協業ができるかもしれません：

```
デザイナー ──┐                  ┌── Figma Make
             │    プロトコル     │
             ├───（共通言語）────┤
             │                  │
エンジニア ──┘                  └── Claude
```

- デザイナーとエンジニアが **同じドキュメント** を見て会話できる
- 「このボタンの`disabled`条件、こう変えたい」みたいな議論ができる

---

## 考察

### 強み
- **動作ロジックの翻訳ロス解消**: ビジュアルでは伝えにくい条件分岐が明確になる
- **設計意図の曖昧さ排除**: デザイナーの意図がテキストで構造化される

### 課題
- **デザインの詳細度の限界**: 色やアニメーションは別途指定が必要
- **メンテナンスコスト**: 複雑になるとYAML自体が複雑になる
- **仕様が固まっていない**: まだ「俺々フォーマット」レベル

---

## まとめ

- Figma等のビジュアルツールでは「動作」をAIに伝えきれない
- 宣言的なテキスト形式で動作を定義すると、AIが解釈しやすい（仮説）
- Figma Make と Claude の両方で検証予定

まだ実験段階で、これが正解かどうかはわかりません。AIの進化で不要になるかもしれないし、全然違うアプローチの方が良いかもしれない。

でも「動くUIをAIに伝える」という課題は確実にあるので、試行錯誤を続けていきます。
